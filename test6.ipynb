{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a87cdb-a321-48e9-bca2-eb6844e62596",
   "metadata": {
    "id": "86a87cdb-a321-48e9-bca2-eb6844e62596"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "#pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3cc02c-6727-4ead-9471-29e668102228",
   "metadata": {
    "id": "6b3cc02c-6727-4ead-9471-29e668102228"
   },
   "outputs": [],
   "source": [
    "gm = pd.read_parquet('gmgm.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c5ea77-9877-4c5a-9dc6-5c6c8127c44a",
   "metadata": {
    "id": "91c5ea77-9877-4c5a-9dc6-5c6c8127c44a",
    "outputId": "27e20558-c4cf-4653-cbcc-9f4dd9661378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17143447, 63)\n",
      "protocol_0           float32\n",
      "protocol_6           float32\n",
      "protocol_17          float32\n",
      "flow_duration        float32\n",
      "flow_byts_s          float32\n",
      "flow_pkts_s          float32\n",
      "fwd_pkts_s           float32\n",
      "bwd_pkts_s           float32\n",
      "tot_fwd_pkts         float32\n",
      "tot_bwd_pkts         float32\n",
      "totlen_fwd_pkts      float32\n",
      "totlen_bwd_pkts      float32\n",
      "fwd_pkt_len_max      float32\n",
      "fwd_pkt_len_min      float32\n",
      "fwd_pkt_len_mean     float32\n",
      "fwd_pkt_len_std      float32\n",
      "bwd_pkt_len_max      float32\n",
      "bwd_pkt_len_min      float32\n",
      "bwd_pkt_len_mean     float32\n",
      "bwd_pkt_len_std      float32\n",
      "pkt_len_max          float32\n",
      "pkt_len_min          float32\n",
      "pkt_len_mean         float32\n",
      "pkt_len_std          float32\n",
      "pkt_len_var          float32\n",
      "fwd_seg_size_min     float32\n",
      "fwd_act_data_pkts    float32\n",
      "flow_iat_mean        float32\n",
      "flow_iat_max         float32\n",
      "flow_iat_min         float32\n",
      "flow_iat_std         float32\n",
      "fwd_iat_tot          float32\n",
      "fwd_iat_max          float32\n",
      "fwd_iat_min          float32\n",
      "fwd_iat_mean         float32\n",
      "fwd_iat_std          float32\n",
      "bwd_iat_tot          float32\n",
      "bwd_iat_max          float32\n",
      "bwd_iat_min          float32\n",
      "bwd_iat_mean         float32\n",
      "bwd_iat_std          float32\n",
      "fwd_psh_flags        float32\n",
      "bwd_psh_flags        float32\n",
      "fin_flag_cnt         float32\n",
      "syn_flag_cnt         float32\n",
      "rst_flag_cnt         float32\n",
      "psh_flag_cnt         float32\n",
      "ack_flag_cnt         float32\n",
      "urg_flag_cnt         float32\n",
      "ece_flag_cnt         float32\n",
      "cwr_flag_count       float32\n",
      "down_up_ratio        float32\n",
      "init_fwd_win_byts    float32\n",
      "init_bwd_win_byts    float32\n",
      "active_max           float32\n",
      "active_min           float32\n",
      "active_mean          float32\n",
      "active_std           float32\n",
      "idle_max             float32\n",
      "idle_min             float32\n",
      "idle_mean            float32\n",
      "idle_std             float32\n",
      "Label                  int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)    # Display all rows (in case you use .head())\n",
    "pd.set_option('display.max_columns', None) # Display all columns\n",
    "pd.set_option('display.width', 1000)\n",
    "print(gm.shape)\n",
    "print(gm.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8e0318-576b-460c-be27-b9c76c855200",
   "metadata": {
    "id": "ae8e0318-576b-460c-be27-b9c76c855200",
    "outputId": "d1083071-05b2-4aac-b50d-b9aede2d48f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating Label...\n",
      "Separation Done. RAM cleaned.\n"
     ]
    }
   ],
   "source": [
    "import gc # Garbage Collector interface\n",
    "\n",
    "print(\"Separating Label...\")\n",
    "\n",
    "# 1. Rip the 'Label' column out of 'gm' and put it into 'y'.\n",
    "# This modifies 'gm' instantly. 'gm' no longer has the label.\n",
    "y = gm.pop('Label') \n",
    "\n",
    "# 2. Now 'gm' IS your 'X' (features only). Just rename the variable.\n",
    "X = gm \n",
    "\n",
    "# 3. Delete the reference to the name 'gm'\n",
    "del gm \n",
    "\n",
    "# 4. Force Python to release memory immediately\n",
    "gc.collect()\n",
    "\n",
    "print(\"Separation Done. RAM cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbcbe04-3cbe-4315-a08d-7131571f4b36",
   "metadata": {
    "id": "9cbcbe04-3cbe-4315-a08d-7131571f4b36"
   },
   "outputs": [],
   "source": [
    "#split data 80:20 for train and temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.20,\n",
    "    stratify = y,\n",
    "    random_state = 42,\n",
    "    shuffle = True # shuffle code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be615475-dc33-4edb-9a51-e6820f1839e9",
   "metadata": {
    "id": "be615475-dc33-4edb-9a51-e6820f1839e9"
   },
   "outputs": [],
   "source": [
    "#split temp 1:1 for validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size = 0.50,\n",
    "    stratify = y_temp,\n",
    "    random_state = 42,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5422235b-3c56-4430-86b5-36f12d61183f",
   "metadata": {
    "id": "5422235b-3c56-4430-86b5-36f12d61183f",
    "outputId": "6dcc5b43-276f-43c5-bd82-63d7ed777eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Scaled Data for DNN/SVM ---\n",
      "Data Scaled. Ready for DNN/SVM.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Creating Scaled Data for DNN/SVM ---\")\n",
    "\n",
    "# 1. Log Transform (Compress the huge numbers)\n",
    "# We create NEW variables so we don't mess up the raw data for trees\n",
    "X_train_scaled = np.log1p(X_train)\n",
    "X_val_scaled   = np.log1p(X_val)\n",
    "\n",
    "# 2. Standard Scaler (Center around 0)\n",
    "scaler_dnn = StandardScaler()\n",
    "X_train_scaled = scaler_dnn.fit_transform(X_train_scaled)\n",
    "X_val_scaled   = scaler_dnn.transform(X_val_scaled)\n",
    "\n",
    "print(\"Data Scaled. Ready for DNN/SVM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcc900-4c0a-4242-9eaa-1baa5ee44172",
   "metadata": {
    "id": "2ebcc900-4c0a-4242-9eaa-1baa5ee44172",
    "outputId": "2481d118-b296-4c5f-e30c-8bee3bba3d57"
   },
   "outputs": [],
   "source": [
    "# #pca\n",
    "# pca = PCA(n_components = 0.95)\n",
    "# X_train_pca = pca.fit_transform(X_train)\n",
    "# X_val_pca = pca.transform(X_val)\n",
    "# X_test_pca = pca.transform(X_test)\n",
    "# print(\"pca done\")\n",
    "# joblib.dump(pca, 'pca_brain.joblib')\n",
    "# print(\"Step 1 Done: PCA saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23cdea6-0d62-4862-99ba-e15954ba6d47",
   "metadata": {
    "id": "2iB1UCmLiHj-"
   },
   "outputs": [],
   "source": [
    "Classifier_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a97023-967d-42df-9e6a-825660c29213",
   "metadata": {
    "id": "N8Jlxv7AiygZ"
   },
   "outputs": [],
   "source": [
    "#TRAINING DNN\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b0214f-7e4f-4d78-89ac-7edce71844b9",
   "metadata": {
    "id": "19b0214f-7e4f-4d78-89ac-7edce71844b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 16:41:02.463257: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-18 16:41:02.463447: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-18 16:41:02.488478: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 16:41:03.069940: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-18 16:41:03.070121: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/naeem/mmkernel/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "/home/naeem/mmkernel/lib/python3.13/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766047263.880290 1219242 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1766047263.885740 1219242 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training DNN on SCALED Data ---\n",
      "Epoch 1/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0153 - val_accuracy: 0.9976 - val_loss: 0.0068\n",
      "Epoch 2/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 0.9979 - val_loss: 0.0063\n",
      "Epoch 3/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0072 - val_accuracy: 0.9978 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9981 - val_loss: 0.0055\n",
      "Epoch 5/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9979 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9984 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.9979 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9982 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9982 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "\u001b[1m6697/6697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9983 - val_loss: 0.0045\n",
      "\u001b[1m53574/53574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 240us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    438449\n",
      "           1       1.00      1.00      1.00   1275896\n",
      "\n",
      "    accuracy                           1.00   1714345\n",
      "   macro avg       1.00      1.00      1.00   1714345\n",
      "weighted avg       1.00      1.00      1.00   1714345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# 1. Weights\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "dnn_weights = {0: weights[0], 1: weights[1]}\n",
    "\n",
    "# 2. Build Model\n",
    "model_dnn = keras.Sequential([\n",
    "    # This was the broken line. It should look exactly like this:\n",
    "    layers.InputLayer(input_shape=(X_train_scaled.shape[1],)), \n",
    "    \n",
    "    layers.Dense(128, activation='relu'), \n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_dnn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 3. Train\n",
    "print(\"--- Training DNN on SCALED Data ---\")\n",
    "history = model_dnn.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=2048, \n",
    "    class_weight=dnn_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred_probs = model_dnn.predict(X_val_scaled)\n",
    "y_pred_dnn = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_val, y_pred_dnn))\n",
    "\n",
    "# 5. Save\n",
    "model_dnn.save('dnn_model_scaled.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac581e-8509-4976-bce0-c36c81793a95",
   "metadata": {
    "id": "TsNxtJYLiXap"
   },
   "outputs": [],
   "source": [
    "#TRAINING KNN AND SVC\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4967f75-7456-483d-b520-a97558e0849b",
   "metadata": {
    "id": "f4967f75-7456-483d-b520-a97558e0849b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training SVM on SCALED Subset ---\n",
      "Predicting SVM...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    438449\n",
      "           1       1.00      0.99      1.00   1275896\n",
      "\n",
      "    accuracy                           0.99   1714345\n",
      "   macro avg       0.99      0.99      0.99   1714345\n",
      "weighted avg       0.99      0.99      0.99   1714345\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_final_scaled.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# 1. Create Scaled Subset\n",
    "# We take the first 50k rows of the ALREADY SCALED data\n",
    "X_train_scaled_small = X_train_scaled[:50000]\n",
    "y_train_small = y_train[:50000]\n",
    "\n",
    "print(\"--- Training SVM on SCALED Subset ---\")\n",
    "\n",
    "# We use class_weight='balanced' to handle the 75/25 split\n",
    "svc_clf = SVC(class_weight='balanced', kernel='rbf', cache_size=2000)\n",
    "\n",
    "svc_clf.fit(X_train_scaled_small, y_train_small)\n",
    "\n",
    "# Evaluate on a portion of validation (to be fast) or full validation\n",
    "print(\"Predicting SVM...\")\n",
    "y_pred_svm = svc_clf.predict(X_val_scaled) # <--- Predict on SCALED validation\n",
    "\n",
    "print(classification_report(y_val, y_pred_svm))\n",
    "\n",
    "joblib.dump(svc_clf, 'svm_final_scaled.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5052cc5-367b-4da0-b95a-cded88525bd6",
   "metadata": {
    "id": "c5052cc5-367b-4da0-b95a-cded88525bd6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cd302-efc3-4b6a-a7f4-d6f4b3e3c491",
   "metadata": {
    "id": "010cd302-efc3-4b6a-a7f4-d6f4b3e3c491"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed68e0f-8d98-4b17-86d6-92eb96ccd7b8",
   "metadata": {
    "id": "aed68e0f-8d98-4b17-86d6-92eb96ccd7b8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420872c-e263-46f1-a3ac-ee1cfb892359",
   "metadata": {
    "id": "2420872c-e263-46f1-a3ac-ee1cfb892359"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ddc605-1dcf-477e-adc3-2698d2c97182",
   "metadata": {
    "id": "55ddc605-1dcf-477e-adc3-2698d2c97182"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3c7e0-3216-40a2-96b2-2e9b54767f2b",
   "metadata": {
    "id": "53e3c7e0-3216-40a2-96b2-2e9b54767f2b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf67d41-f370-4b88-b8c5-f303803f8854",
   "metadata": {
    "id": "8cf67d41-f370-4b88-b8c5-f303803f8854"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "markernel",
   "language": "python",
   "name": "mmkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
